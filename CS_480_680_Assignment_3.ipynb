{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zalsaigh/cs480/blob/main/CS_480_680_Assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CS 480/680 assignment 3\n",
        "\n",
        "Tips:\n",
        "- Please save a copy of this notebook to avoid losing your changes.\n",
        "- Debug your code and ensure that it can run.\n",
        "- Save the output of each cell. Failure to do so may result in your coding questions not being graded.\n",
        "- To accelerate the training time, you can choose 'Runtime' -> 'Change runtime type' -> 'Hardware accelerator' and set 'Hardware accelerator' to 'GPU'.\n",
        "- Your grade is independent of the accuracy of your models. Your grade will depend on the correctness of your code and implementation.\n",
        "\n",
        "Tips for sumbission:\n",
        "- Do not change the order of the problems.\n",
        "- Select 'Runtime' -> 'Run all' to run all cells and generate a final \"gradable\" version of your notebook and save your ipynb file.\n",
        "- Also use 'File' -> 'Print' and then print your report from your browser into a PDF file."
      ],
      "metadata": {
        "id": "uHZhkDjZEV-5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1 - Implementing GAN for MNIST dataset (35 points)\n",
        "\n",
        "In this question we are going to impelement a generative network that can generate MNIST handwritten digits from random Gaussian noise."
      ],
      "metadata": {
        "id": "GK9gmfL4KxeF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q1.1 (2 points)\n",
        "\n",
        "We start by creating the data loaders. Note that each MNIST image is of size 28\\*28. The **first task** is to build the ```data_loader```"
      ],
      "metadata": {
        "id": "_n-Mg5YdE5YR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "\n",
        "# Setting the device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "batch_size = 100\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "\n",
        "#ToDo: Build the train data loader using the above batch_size varibale and shuffling the dataset.\n",
        "data_loader =\n",
        "\n"
      ],
      "metadata": {
        "id": "z-BU1m9IEXKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q1.2 Generator (5 points)\n",
        "We will be building simple Generator and Discriminators that only consist of fully-connected layers. The Generator takes as input a Gaussian vector with dimension ```n_dim```. It consists of two linear layers with ```256``` and ```512``` nodes and the output layer should of dimension ```28*28=784``` so that it can be considered as unfolding a ```28*28``` image into a vector. The **second task** is to complete the following code for building the Generator."
      ],
      "metadata": {
        "id": "w_-NwpdfFGQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, n_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        #ToDo: Complete the code\n",
        "        #The activation function for the two hidden layers is ReLU.\n",
        "        #The last layer's activation function is Tanh.\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        #ToDo: Complete this function. The function takes as input x and outputs the result of applying the generator on x.\n",
        "\n"
      ],
      "metadata": {
        "id": "uACYmlwwG2tL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q1.3 Discriminator (5 points)\n",
        "The Discriminator takes as input an image of size ```28*28```. It consists of two linear layers with ```512``` and ```256``` nodes and the output layer should be a single node. The **third task** complete the following code for building the Discriminator."
      ],
      "metadata": {
        "id": "InnZY0glITeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "            #ToDo: Complete the code\n",
        "            #The activation functions for the two hidden layers are ReLU.\n",
        "            #The last layer's activation function is Sigmoid.\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1) # Making sure that the batch of images has the shape [batch_size,28*28] instead of [batch_size,1,28,28]\n",
        "        #ToDo: Complete this function. The function takes as input x and outputs the result of applying the generator on x.\n"
      ],
      "metadata": {
        "id": "t5hdsi10JWJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q1.4 Initializaiton (2 points)\n",
        "\n",
        "The **fourth task** is to define the optimizers."
      ],
      "metadata": {
        "id": "SXItGnRYK69p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_dim = 100\n",
        "generator = Generator(n_dim).to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "lr = 0.0002\n",
        "\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "#ToDo: define the two different Adam optimizers for generator and discriminator with learning rates of lr.\n",
        "\n",
        "d_optimizer =\n",
        "g_optimizer ="
      ],
      "metadata": {
        "id": "FyuaaCJLLCdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q1.5 Training (16 points)\n",
        "\n",
        "Note that when applying the ```criterion``` both the inputs should be on the same device. If you are defining a set of labels that you want to use in ```criterion``` you must move them to ```device``` first.\n",
        "\n",
        "Recall from the Goodfellow et al. 2014 that the following happens during the minimax game between Discriminator and the Generator.\n",
        "\n",
        "Discriminator is ascending\n",
        "$\\nabla\\frac{1}{m}\\sum_{i=1}^m\\log D(x^{(i)}) + \\log(1-D(G(z^{(i)})))$ where $D$ and $G$ denote the Districiminator and the Generator, respectively. Here, $x^{1},\\ldots,x^{m}$ is the batch of training examples (i.e., MNIST images) and $z^{(1)},\\ldots,z^{(m)}$ is a batch of random noise.\n",
        "\n",
        "Also note that for two batches $x=\\{x^{1},\\ldots,x^{m}\\}$ and $y=\\{y^{1},\\ldots,y^{m}\\}$ the BCELoss function $l(x,y)$ computes the following.\n",
        "$$l(x,y) = \\frac{1}{m}\\sum_{i=1}^m y^{(i)}\\log x^{(i)} + (1-y^{(i)})\\log (1- x^{(i)})$$\n",
        "\n",
        "The **fifth task** is to make sure that ```d_loss``` is computing the quantity that discriminator wants to ascend. This is achieved by setting ```d_loss = d_loss_real + d_loss_fake``` and letting ```d_loss_real``` to be $\\frac{1}{m}\\sum_{i=1}^m\\log D(x^{(i)})$ and ```d_loss_fake``` to be $\\frac{1}{m}\\sum_{i=1}^m \\log(1-D(G(z^{(i)})))$. Hint: ```d_loss_real``` is already implemented.\n",
        "\n",
        "We now turn to train the generator. Initially, the generator wants to descend the following $\\nabla\\frac{1}{m}\\sum_{i=1}^m \\log(1-D(G(z^{(i)})))$. However, this may affect the training of the generator specifically in the early stages of training where the discriminator can confidently reject the generated examples [Goodfellow et al., 2014]. Instead, we will require the generator to ascend $\\nabla\\frac{1}{m}\\sum_{i=1}^m \\log(D(G(z^{(i)})))$. The **sixth task** is to compute ```g_loss``` used for training the generator.\n"
      ],
      "metadata": {
        "id": "ASpkAhASZs-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1\n",
        "total_step = len(data_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, _) in enumerate(data_loader):\n",
        "        real_images = images.to(device)\n",
        "\n",
        "        # Training discriminator\n",
        "        discriminator.zero_grad()\n",
        "        real_outputs = discriminator(real_images)\n",
        "        real_labels = torch.ones(real_images.size(0), 1).to(device)\n",
        "        d_loss_real = criterion(real_outputs, real_labels)\n",
        "\n",
        "        #ToDo: Compute d_loss_fake\n",
        "\n",
        "\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "\n",
        "        # Training generator\n",
        "        generator.zero_grad()\n",
        "\n",
        "        #ToDo: compute g_loss\n",
        "\n",
        "\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "\n",
        "        if (i+1) % 300 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_step}], '\n",
        "                  f'Discriminator Loss: {d_loss.item():.4f}, '\n",
        "                  f'Generator Loss: {g_loss.item():.4f}')"
      ],
      "metadata": {
        "id": "RA8t-sCQZ8SG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q1.6 Plotting the results (5 points)\n",
        "The **seventh and final task** for this question is to try the trained generator. Generate 4 random vectors, apply the generator on them, and plot the resulting image in a single 2 by 2 plot."
      ],
      "metadata": {
        "id": "q3CGaQzDDRg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "# Your code here"
      ],
      "metadata": {
        "id": "lvUJnaqSJCPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2 - Transformers (65 points)\n",
        "In this question we will be implementing a transformer architecture and apply it on a simple artificially generated dataset."
      ],
      "metadata": {
        "id": "ifoL2LfccMKA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2.1 Multi-Head Attention (9 points)\n",
        "\n",
        "The attention layer works on batches of training data where each training data itself is a sequence of words/token with length at most ```seq_length``` and each word is embedded into a ```d_embedding``` dimensional vector, e.g., later when we run the transformer on the artificial dataset, the inputs to the transformer and attention layer have shapes of ```[batch_size,seq_length,d_embedding]```. Recall from the lecture that a multi-head attention layer consists of ```n_heads``` self-attention heads. The input matrices Query Q, Key K, and Value V to multi-attention head are passed through linear layers $W_Q$, $W_K$, and $W_V$ which are trainable parameters. The multi-head attention will divide the embedding vector of the input into ```n_heads``` vector of size ```d_k``` and use each as an attention head. This is particularly done by the ```make_heads``` function which transforms the input to an output of shape ```[batch_size, n_heads, seq_length, d_k]```. The multi-head attention then computes the probabilities using the input values, which is implemented by the ```compute_attention_probs``` function. It then joins them using the ```join_heads``` function and finally passes them through an output linear layer $W_O$. The **first task** is to implement the ```forward``` function of Multi-Head attention using the functions already implemented."
      ],
      "metadata": {
        "id": "qtZX21CEcu6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import math\n",
        "import copy\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_embedding, n_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        assert d_embedding % n_heads == 0\n",
        "\n",
        "        self.d_embedding = d_embedding\n",
        "        self.n_heads = n_heads\n",
        "        self.d_k = d_embedding // n_heads\n",
        "\n",
        "        self.W_q = nn.Linear(d_embedding, d_embedding)\n",
        "        self.W_k = nn.Linear(d_embedding, d_embedding)\n",
        "        self.W_v = nn.Linear(d_embedding, d_embedding)\n",
        "        self.W_o = nn.Linear(d_embedding, d_embedding)\n",
        "\n",
        "    def compute_attention_probs(self, Q, K, V, mask=None):\n",
        "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "        if mask is not None:\n",
        "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
        "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
        "        output = torch.matmul(attn_probs, V)\n",
        "        return output\n",
        "\n",
        "\n",
        "    def make_heads(self, x):\n",
        "        batch_size, seq_length, d_embedding = x.size()\n",
        "        y=x.view(batch_size, seq_length, self.n_heads, self.d_k).transpose(1, 2)\n",
        "        return x.view(batch_size, seq_length, self.n_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "    def join_heads(self, x):\n",
        "        batch_size, _, seq_length, d_k = x.size()\n",
        "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_embedding)\n",
        "\n",
        "    def forward(self, Q, K, V, mask=None):\n",
        "       #ToDo: Complete code\n",
        "\n"
      ],
      "metadata": {
        "id": "pE_j8e5u4aLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2.2 Feed-forward layer (2 points)\n",
        "The output of the multi-head attention layer is used as an input to the feed-forward layer in the encoder. This layer is implemented in the following class. The **second task** is to complete the ```forward``` function of this class."
      ],
      "metadata": {
        "id": "nT0KE6fB6497"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_embedding, d_ff):\n",
        "        super(FeedForward, self).__init__()\n",
        "        self.fc1 = nn.Linear(d_embedding, d_ff)\n",
        "        self.fc2 = nn.Linear(d_ff, d_embedding)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        #ToDO: Complete code\n"
      ],
      "metadata": {
        "id": "InGgN9XN7muD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2.3 Encoder Block (9 points)\n",
        "\n",
        "We now have all the necessary classes to build the Encoder block. The encoder block gets as input a batch of data. It first passes the input through the multi-attention layer. It then applies 1) a droput layer, 2) adds the input to the output of droupout layer as a residual, 3) applies a layer normalization, 4) and passes the output to the feed-forward layer. Finally, it applies 1) a droput layer, 2) adds the input to the output of droupout layer as a residual, and 3) Applies a layer normalization. The **third task** is to complete the ```forward``` function of this class."
      ],
      "metadata": {
        "id": "uaZ1PCFJ9DXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, d_embedding, n_heads, d_ff, dropout):\n",
        "        super(EncoderBlock, self).__init__()\n",
        "        self.self_attention = MultiHeadAttention(d_embedding, n_heads)\n",
        "        self.feed_forward = FeedForward(d_embedding, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_embedding)\n",
        "        self.norm2 = nn.LayerNorm(d_embedding)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        #ToDo: Complete code\n",
        "        \"\"\"\n",
        "        Returns: The output of encoder on a given input batch x\n",
        "        \"\"\"\n"
      ],
      "metadata": {
        "id": "s0MnjetG_Zum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2.4 Decoder Block (20 points)\n",
        "\n",
        "In this part we will build the decoder block. The **fourth task** is to implement the DecoderBlock. You can refer to the lecture notes to find the architecture of the decoder block including the multi-attention layers, add and norm layers, and the feedforward layer. You can also add a *dropout* layer to the final add and norm layer.\n"
      ],
      "metadata": {
        "id": "jru9E9dZ_aKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, d_embedding, n_heads, d_ff, dropout):\n",
        "        super(DecoderBlock, self).__init__()\n",
        "        \"\"\"\n",
        "        Args:\n",
        "           self_attention: decoder's multi-head attention\n",
        "           cross_attention: The multi-head attention layer between the encoder and the decoder\n",
        "           feed_forward: feed-forward layer\n",
        "           mask: mask to be given for multi head attention\n",
        "           norm1: First Normalization layer\n",
        "           norm2: Second Normalization layer\n",
        "           norm3: Third Normalization layer\n",
        "           dropout: Final dropout layer\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
        "        \"\"\"\n",
        "        Returns: The output of decoder on a given input batch x\n",
        "        \"\"\"\n"
      ],
      "metadata": {
        "id": "HCX_D3xoFYJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2.5 Transformer Block (20 points)\n",
        "\n",
        "Finally, we use the classes defined for EncoderBlock and DecoderBlock to build the TransformerBlock. The **fifth task** is to complete the ```forward``` function of this class. Note that ```num_layers``` indicates the number of encoder and decoder layers in the transformer. You can refer to the final architecture of the Transformer from the lectures. You can also include a dropout layer after embedding the source and target inputs. Remember to apply positional encoding to the input batch before passing it to the transformer."
      ],
      "metadata": {
        "id": "UyH9ROxRI252"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_embedding, max_seq_length):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        pe = torch.zeros(max_seq_length, d_embedding)\n",
        "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_embedding, 2).float() * -(math.log(10000.0) / d_embedding))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_embedding, n_heads, num_layers, d_ff, max_seq_length, dropout):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_embedding)\n",
        "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_embedding)\n",
        "        self.positional_encoding = PositionalEncoding(d_embedding, max_seq_length)\n",
        "\n",
        "        self.encoder_layers = nn.ModuleList([EncoderBlock(d_embedding, n_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.decoder_layers = nn.ModuleList([DecoderBlock(d_embedding, n_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "\n",
        "        self.fc = nn.Linear(d_embedding, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    # Masking the input; the outputs returned by this function should be passed to encoder and decoder layers\n",
        "    def generate_mask(self, src, tgt):\n",
        "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
        "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
        "        seq_length = tgt.size(1)\n",
        "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n",
        "        tgt_mask = tgt_mask & nopeak_mask\n",
        "        return src_mask, tgt_mask\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        #ToDo: complete the code\n",
        "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
        "        \"\"\"\n",
        "        Returns: The output of transformer on a given input batch x\n",
        "        \"\"\"\n"
      ],
      "metadata": {
        "id": "2Sz2JAuwmnNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2.6 Training (5 points)\n",
        "We can now train the model on an imaginary randomly generated dataset. The **sixth task** is to complete the training code and plot the training loss."
      ],
      "metadata": {
        "id": "dGtuTlqWms4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab_size = 5000\n",
        "tgt_vocab_size = 5000\n",
        "d_embedding = 512\n",
        "n_heads = 8\n",
        "num_layers = 6\n",
        "d_ff = 2048\n",
        "max_seq_length = 100\n",
        "dropout = 0.1\n",
        "\n",
        "transformer = Transformer(src_vocab_size, tgt_vocab_size, d_embedding, n_heads, num_layers, d_ff, max_seq_length, dropout)\n",
        "\n",
        "# Generate random sample data\n",
        "src_data = torch.randint(1, src_vocab_size, (64, max_seq_length))\n",
        "tgt_data = torch.randint(1, tgt_vocab_size, (64, max_seq_length))\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
        "\n",
        "transformer.train()\n",
        "\n",
        "for epoch in range(25):\n",
        "   #ToDo: complete the code\n"
      ],
      "metadata": {
        "id": "94xoG6QF5gnv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}